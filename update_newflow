#!/usr/bin/python3

import os
import sys

# TODO: There's a bug in month/day order in the newer data dumps. Let's get one
# from the history for now.
SRC_URL = "https://github.com/globaldothealth/list/raw/14d1f99394842794d7184e3423eaa18e68b275d7/data/cases.tar.gz"
#SRC_URL = "https://github.com/globaldothealth/list/raw/main/data/cases.tar.gz"

CASES_FILE_NAME = "cases.json"
LOCATION_INFO_FILE_NAME = "location_info.data"
SELF_DIR = os.path.dirname(os.path.realpath(__file__))

def check_for_common_repo():
    if not os.path.exists("../common"):
        print("Please clone the 'common' repo as a sibling of this one:")
        print("cd .. && git clone git@github.com:globaldothealth/common.git")
        return False
    return True

def update():
    if os.path.exists(CASES_FILE_NAME):
        print(CASES_FILE_NAME + " exists, not re-downloading.")
    else:
        os.system("wget '" + SRC_URL + "'")
        os.system("tar xzf cases.tar.gz")

    print("Loading cases...")
    cases = processor.load_case_data(CASES_FILE_NAME)
    print("Loaded " + str(len(cases)) + " cases")
    print("Extracting location data...")
    processor.extract_location_info(cases, LOCATION_INFO_FILE_NAME)
    os.system("../common/tools/sanitize_location_info")

    print("Pruning data...")
    pruned_cases = processor.prune_cases(cases)

    processor.output_daily_slices(pruned_cases,
                                  os.path.join(SELF_DIR, "d"),)
    # TODO: Also output country slices.
    # os.system("rm " + os.path.join(SELF_DIR, "c") + "/*")
    # processor.output_country_slices(pruned_cases,
                                    # os.path.join(SELF_DIR, "c"))
    # print(pruned_cases)

if __name__ == "__main__":
    if check_for_common_repo():
        print("Importing common tools")
        sys.path.insert(0, "../common/tools")
        from tools import case_data_processor as processor
        import geo_util
        geo_util.clean()
        update()
